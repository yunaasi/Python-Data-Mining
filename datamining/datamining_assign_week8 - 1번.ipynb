{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터마이닝 7주차 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 도요타 자동차(ToyotaCorolla.csv)를 이용하여 아래 두 문항에 대해 답하시오.\n",
    "https://github.com/reisanar/datasets/blob/master/ToyotaCorolla.csv\n",
    "### ① 선형회귀모델을 구축하시오.\n",
    "i. 1000개의 인스턴스를 이용하시오.\n",
    "ii. ‘age_08_04’, ‘km’, ‘fuel_type’, ‘hp’, ‘met_color’, ‘automatic’, ‘cc’, doors’,‘quarterly_tax’, ‘weight’ 변수를 이용하여 ‘price’를 예측하시오.\n",
    "iii. Training dataset과 test dataset을 7:3으로 분할하고, 이 때 random_state는 42로 설정하시오.\n",
    "iv. 각 변수에 대한 coefficient를 도출하시오.\n",
    "v. Test dataset에 대한 모델의 MSE 및 MAE 값을 도출하시오.\n",
    "\n",
    ">경로\n",
    "/Users/shimyuna/Desktop/✳︎/Python-Data-Mining/datamining/ToyotaCorolla.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # 훈련/평가 분할\n",
    "from sklearn.metrics import r2_score # 결정계수 함수 (이 통계 모델로 대상을 얼마나 잘 설명할 수 있는가를 숫자로 나타낸 것이 결정계수이다.)\n",
    "from sklearn.linear_model import LinearRegression #선형 회귀 분석\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "#데이터로부터 데이터 셋을 생성하고, 불러오는 코드\n",
    "Toyota_df = pd.read_csv(\"/Users/shimyuna/Desktop/✳︎/Python-Data-Mining/datamining/ToyotaCorolla.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept -6.439222488552332e-10\n",
      "           predictor   coefficient\n",
      "0          age_08_04  2.809117e-14\n",
      "1                 km  1.024181e-14\n",
      "2                 hp  3.944764e-14\n",
      "3          met_color -5.222718e-14\n",
      "4          automatic  1.637817e-13\n",
      "5                 cc -1.098026e-16\n",
      "6              doors  2.615235e-14\n",
      "7      quarterly_tax  1.359769e-14\n",
      "8             weight -3.790100e-16\n",
      "9              price  1.000000e+00\n",
      "10  fuel_type_Diesel -1.126410e-13\n",
      "11  fuel_type_Petrol -4.672758e-14\n",
      "\n",
      "\n",
      "MSE:  1.185797708517499e-19\n",
      "MAE:  2.6208605656089884e-10\n"
     ]
    }
   ],
   "source": [
    "#1) 100개의 인스턴스만 사용 \n",
    "#2) 'age_08_04','km','fuel_type','hp','met_color','automatic','cc','doors','quarterly_tax','weight' 변수를 이용하여 'price'예측\n",
    "#3) Training dataset과 test dataset을 7:3으로 분할하고, 이때 random_state는 42로 설정하시오\n",
    "#4) 각 변수에 대한 coefficient를 도출\n",
    "# 5) Test dataset에 대한 모델의 MSE 및 MAE 값을 도출\n",
    "\n",
    "Toyota_df = Toyota_df.iloc[:1000] # 처음부터 1000번째 행까지 추출\n",
    "\n",
    "# 회귀분석을 위한 열 선택\n",
    "predictors = ['age_08_04','km','fuel_type','hp','met_color','automatic','cc','doors','quarterly_tax','weight','price']\n",
    "outcome = 'price'\n",
    "\n",
    "# 데이터 분할\n",
    "X = pd.get_dummies(Toyota_df[predictors], drop_first=True)\n",
    "y = Toyota_df[outcome]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 선형 회귀 모델 학습\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# coefficients 출력\n",
    "print('intercept', model.intercept_)\n",
    "print(pd.DataFrame({'predictor' : X.columns, 'coefficient': model.coef_}))\n",
    "\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# MSE와 MAE 계산\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('\\n')\n",
    "print(\"MSE: \", mse)\n",
    "print(\"MAE: \", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ② Ridge와 Lasso의 차이에 대해 간략히 서술하시오.\n",
    "\n",
    "> Ridge 회귀와 Lasso 회귀는 둘 다 선형 회귀 모델의 일종으로 이 두 모델의 차이는 회귀 계수를 제한하는 방법이다. Ridge 회귀는 회귀 계수를 축소하지만 0(0으로 근접시킴)으로 만들지는 않으며, Lasso 회귀는 회귀 계수를 축소하고 0으로 만들 수 있다.\n",
    "\n",
    "Ridge 회귀는 L2 규제를 사용하여 회귀 계수를 제한한다. L2 규제는 모든 회귀 계수에 대해 큰 값을 가지는 페널티를 부여하여, 회귀 계수의 크기를 작게 만든다. Ridge 회귀는 이를 통해 모델의 복잡도를 감소시키고 일반화 성능을 향상시킨다.\n",
    "\n",
    "Lasso 회귀는 L1 규제를 사용하여 회귀 계수를 제한한다. L1 규제는 일부 회귀 계수만을 큰 값을 가지는 페널티를 부여하여, 회귀 계수의 크기를 0으로 만든다. 따라서 Lasso 회귀는 회귀 계수를 0으로 만들어 feature selection의 효과를 가질 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
